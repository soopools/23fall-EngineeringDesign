{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import skimage\n",
    "from skimage import io\n",
    "from skimage import img_as_ubyte\n",
    "from matplotlib import pyplot as plt\n",
    "from skimage import data\n",
    "from skimage.transform import resize\n",
    "from skimage.metrics import peak_signal_noise_ratio, structural_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gaussian Filter\n",
    "\n",
    "def gaussian_kernel(k_size, sigma):\n",
    "    size = k_size//2\n",
    "    y, x = np.ogrid[-size:size+1, -size:size+1]\n",
    "    filter = 1/(2*np.pi * (sigma**2)) * np.exp(-1 *(x**2 + y**2)/(2*(sigma**2)))\n",
    "    sum = filter.sum()\n",
    "    filter /= sum\n",
    "    return filter\n",
    "\n",
    "def padding(img, k_size):\n",
    "    pad_size = k_size//2\n",
    "    h, w, ch = img.shape\n",
    "    \n",
    "    res = np.zeros((h + (2*pad_size), w+(2*pad_size), ch), dtype=np.float)\n",
    "    \n",
    "    if pad_size == 0:\n",
    "        res = img.copy()\n",
    "    else:\n",
    "        res[pad_size:-pad_size, pad_size:-pad_size] = img.copy()\n",
    "    return res\n",
    "\n",
    "def gaussian_filtering(img, k_size=5,sigma=4):\n",
    "    h, w, ch = img.shape\n",
    "    filter = gaussian_kernel(k_size, sigma)\n",
    "    pad_img = padding(img,k_size)\n",
    "    filtered_img = np.zeros((h, w, ch), dtype=np.float32)\n",
    "    \n",
    "    for ch in range(0, ch):\n",
    "        for i in range(h):\n",
    "            for j in range(w):\n",
    "                filtered_img[i, j, ch] = np.sum(filter * pad_img[i:i+k_size, j:j+k_size, ch])\n",
    "\n",
    "    return filtered_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def median_filter(img, filter_size=(3, 3), stride=1):\n",
    "    \n",
    "    img_shape = np.shape(img) # 이미지 크기 가져오기\n",
    "\n",
    "    # 결과 이미지의 형태를 계산합니다.\n",
    "    # 여기서 filter_size와 stride를 고려하여 결과 이미지의 각 차원 크기를 계산합니다.\n",
    "    result_shape = tuple(np.int64((np.array(img_shape[:2]) - np.array(filter_size)) / stride) + 1) + (img_shape[2],)\n",
    "\n",
    "    # 결과 이미지를 저장할 배열을 초기화합니다.\n",
    "    result = np.zeros(result_shape)\n",
    "\n",
    "    # 이미지를 순회하면서 각 픽셀에 대해 메디안 필터를 적용합니다.\n",
    "    for h in range(0, result_shape[0], stride):\n",
    "        for w in range(0, result_shape[1], stride):\n",
    "            for c in range(img_shape[2]):\n",
    "                # 현재 위치에서 필터 크기만큼의 영역을 추출합니다.\n",
    "                tmp = img[h:h + filter_size[0], w:w + filter_size[1], c].ravel()\n",
    "                \n",
    "                # 추출된 영역의 값을 정렬합니다.\n",
    "                tmp = np.sort(tmp)\n",
    "\n",
    "                # 정렬된 값 중 중앙값을 결과 이미지의 해당 위치에 할당합니다.\n",
    "                result[h, w, c] = tmp[int(len(tmp) / 2)]\n",
    "\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fast_bilateral_filter(noisy_img, k_size=5, sigma_space=4, sigma_intensity=0.2):\n",
    "    h, w, ch = noisy_img.shape\n",
    "    bilateral_noisy_img = np.zeros((h, w, ch))\n",
    "\n",
    "    spatial_filter = gaussian_kernel(k_size, sigma_space)\n",
    "\n",
    "    for c in range(ch):\n",
    "        intensity_center = noisy_img[:, :, c]\n",
    "        weighted_sum = np.zeros_like(intensity_center)\n",
    "        normalization_factor = np.zeros_like(intensity_center)\n",
    "\n",
    "        for m in range(-k_size//2, k_size//2 + 1):\n",
    "            for n in range(-k_size//2, k_size//2 + 1):\n",
    "                i_neighbors = np.clip(np.arange(h) + m, 0, h - 1)\n",
    "                j_neighbors = np.clip(np.arange(w) + n, 0, w - 1)\n",
    "                intensity_neighbors = noisy_img[i_neighbors, :, c][:, j_neighbors]\n",
    "                weight_intensity = np.exp(-(intensity_center - intensity_neighbors)**2 / (2 * sigma_intensity**2))\n",
    "                weight_spatial = spatial_filter[m + k_size//2, n + k_size//2]\n",
    "                weighted_sum += intensity_neighbors * weight_intensity * weight_spatial\n",
    "                normalization_factor += weight_intensity * weight_spatial\n",
    "\n",
    "        bilateral_noisy_img[:, :, c] = weighted_sum / normalization_factor\n",
    "    return bilateral_noisy_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/n1/t3hm6b612gg69mlfjrdv4ht00000gn/T/ipykernel_8214/3250497239.py:15: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  res = np.zeros((h + (2*pad_size), w+(2*pad_size), ch), dtype=np.float)\n"
     ]
    }
   ],
   "source": [
    "def process_and_evaluate_image(clean_img, noisy_img, filter_size, k_size, sigma, sigma_space, sigma_intensity):\n",
    "    median_img = median_filter(noisy_img, filter_size, 1)\n",
    "    median_img_resized = resize(median_img, clean_img.shape, mode='constant', anti_aliasing=True)\n",
    "    median_img_resized = np.clip(median_img_resized, 0., 1.0)\n",
    "\n",
    "    gaussian_img = gaussian_filtering(median_img_resized, k_size=k_size, sigma=sigma)\n",
    "    bilateral_img = fast_bilateral_filter(gaussian_img, k_size=k_size, sigma_space=sigma_space, sigma_intensity=sigma_intensity)\n",
    "    bilateral_img = np.clip(bilateral_img, 0., 1.)\n",
    "\n",
    "    psnr = peak_signal_noise_ratio(clean_img, bilateral_img)\n",
    "    ssim = structural_similarity(clean_img, bilateral_img, channel_axis=2, full=False)\n",
    "    \n",
    "    return psnr, ssim, bilateral_img\n",
    "\n",
    "# 메인 코드\n",
    "name = ['baby', 'bagles', 'beach', 'book', 'dog', 'girl_ani', 'lego', 'kitty', 'house', 'street']\n",
    "png = '.png'\n",
    "\n",
    "for fn in name:\n",
    "    clean_img = io.imread(fn + png).astype(float)[:, :, 0:3] / 255.0\n",
    "    noisy_img = io.imread(fn + '_noisy' + png).astype(float)[:, :, 0:3] / 255.0\n",
    "\n",
    "    max_psnr, max_ssim = 0, 0\n",
    "    max_psnr_img, max_ssim_img = None, None\n",
    "\n",
    "    for mfs in [3, 5]:\n",
    "        for k_size in [3, 5, 7]:\n",
    "            for sigma in [1, 3, 5]:\n",
    "                for sigma_space in [3, 5, 7]:\n",
    "                    for sigma_intensity in [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0]:\n",
    "                        psnr, ssim, img = process_and_evaluate_image(clean_img, noisy_img, (mfs, mfs), k_size, sigma, sigma_space, sigma_intensity)\n",
    "\n",
    "                        if psnr > max_psnr:\n",
    "                            max_psnr = psnr\n",
    "                            max_psnr_img = img\n",
    "                        if ssim > max_ssim:\n",
    "                            max_ssim = ssim\n",
    "                            max_ssim_img = img\n",
    "\n",
    "    plt.imsave(f'max_psnr_{fn}{png}', max_psnr_img)\n",
    "    plt.imsave(f'max_ssim_{fn}{png}', max_ssim_img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
